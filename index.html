<!DOCTYPE html>
<html>
<head>
  <title>AI Ski Coach - Slope Logic</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
      text-align: center;
      padding: 2em;
      background-color: #f4f7f6;
      color: #333;
    }
    .hidden {
      display: none !important;
    }
    #playerContainer {
      position: relative;
      width: 100%;
      max-width: 720px;
      min-height: 400px;
      margin: 20px auto;
      background-color: #000;
      border-radius: 8px;
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    #resultsVideo {
      width: 100%;
      height: auto;
      display: block;
      position: relative;
      z-index: 1;
    }
    #resultsCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
      z-index: 2;
    }
    #processingCanvas {
      display: none;
    }
    #status {
      margin: 20px auto;
      padding: 10px;
      max-width: 720px;
      background: #fff;
      border-radius: 8px;
      font-size: 14px;
      color: #666;
    }
    .upload-btn {
      padding: 12px 24px;
      background: linear-gradient(135deg, #667eea, #764ba2);
      color: white;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      font-size: 16px;
      margin: 20px 0;
    }
    .upload-btn:hover {
      opacity: 0.9;
    }
    input[type="file"] {
      display: none;
    }
    .settings {
      max-width: 720px;
      margin: 20px auto;
      padding: 15px;
      background: #fff;
      border-radius: 8px;
      text-align: left;
    }
    .settings label {
      display: block;
      margin: 10px 0 5px;
      font-weight: 500;
    }
    .settings input[type="range"] {
      width: 100%;
    }
    .settings-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin: 5px 0;
    }
    .info-badge {
      display: inline-block;
      background: #4CAF50;
      color: white;
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 12px;
      margin-left: 10px;
    }
  </style>
</head>
<body>
  <h1>AI Ski Coach</h1>
  <p>Upload your ski video and watch the AI analyze your form in real-time.</p>
  <p style="font-size: 14px; color: #666;">
    Advanced tracking with temporal smoothing & Kalman filtering
    <span class="info-badge">Optimized for distant skiers</span>
  </p>

  <label for="videoUpload" class="upload-btn">Choose Video File</label>
  <input type="file" id="videoUpload" accept="video/*">

  <div class="settings">
    <h3 style="margin-top: 0;">Detection Settings</h3>
    <div class="settings-row">
      <label for="contrast">Contrast Enhancement:</label>
      <span id="contrastValue">1.3</span>
    </div>
    <input type="range" id="contrast" min="1" max="2" step="0.1" value="1.3">

    <div class="settings-row">
      <label for="brightness">Brightness:</label>
      <span id="brightnessValue">1.1</span>
    </div>
    <input type="range" id="brightness" min="0.8" max="1.5" step="0.1" value="1.1">

    <div class="settings-row">
      <label for="sharpness">Sharpness:</label>
      <span id="sharpnessValue">1.5</span>
    </div>
    <input type="range" id="sharpness" min="0" max="3" step="0.5" value="1.5">

    <div class="settings-row">
      <label for="smoothing">Temporal Smoothing:</label>
      <span id="smoothingValue">0.3</span>
    </div>
    <input type="range" id="smoothing" min="0" max="1" step="0.1" value="0.3">
  </div>

  <div id="status"></div>

  <div id="playerContainer" class="hidden">
    <video id="resultsVideo" controls playsinline></video>
    <canvas id="resultsCanvas"></canvas>
  </div>

  <canvas id="processingCanvas"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5.1675469404/pose.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3.1620248257/drawing_utils.js" crossorigin="anonymous"></script>

  <script>
    const status = document.getElementById('status');

    function log(message) {
      console.log(message);
      status.textContent = message;
    }

    // Kalman Filter for 2D point tracking
    class KalmanFilter {
      constructor() {
        this.x = 0; // position x
        this.y = 0; // position y
        this.vx = 0; // velocity x
        this.vy = 0; // velocity y
        this.initialized = false;

        // Process noise
        this.processNoise = 0.01;
        // Measurement noise
        this.measurementNoise = 0.1;

        // Error covariance
        this.p = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]];
      }

      update(mx, my) {
        if (!this.initialized) {
          this.x = mx;
          this.y = my;
          this.initialized = true;
          return { x: mx, y: my };
        }

        // Predict
        const predictedX = this.x + this.vx;
        const predictedY = this.y + this.vy;

        // Update with measurement
        const kx = this.p[0][0] / (this.p[0][0] + this.measurementNoise);
        const ky = this.p[1][1] / (this.p[1][1] + this.measurementNoise);

        this.x = predictedX + kx * (mx - predictedX);
        this.y = predictedY + ky * (my - predictedY);

        this.vx = (1 - kx) * this.vx + kx * (mx - predictedX);
        this.vy = (1 - ky) * this.vy + ky * (my - predictedY);

        // Update error covariance
        this.p[0][0] = (1 - kx) * this.p[0][0] + this.processNoise;
        this.p[1][1] = (1 - ky) * this.p[1][1] + this.processNoise;

        return { x: this.x, y: this.y };
      }

      predict() {
        if (!this.initialized) return null;
        return { x: this.x + this.vx, y: this.y + this.vy };
      }
    }

    // Temporal Smoothing System
    class TemporalSmoother {
      constructor(historySize = 10, maxGapFrames = 5) {
        this.historySize = historySize;
        this.maxGapFrames = maxGapFrames;
        this.history = [];
        this.kalmanFilters = {}; // One filter per landmark
        this.missingFrames = {}; // Track missing frames per landmark
      }

      addFrame(landmarks) {
        this.history.push({
          landmarks: landmarks ? JSON.parse(JSON.stringify(landmarks)) : null,
          timestamp: Date.now()
        });

        if (this.history.length > this.historySize) {
          this.history.shift();
        }
      }

      smooth(currentLandmarks, smoothingFactor = 0.7) {
        if (!currentLandmarks) {
          // No detection - try to interpolate from history
          return this.interpolateFromHistory();
        }

        const smoothedLandmarks = [];

        currentLandmarks.forEach((landmark, i) => {
          // Initialize Kalman filter if needed
          if (!this.kalmanFilters[i]) {
            this.kalmanFilters[i] = new KalmanFilter();
          }

          // Apply Kalman filtering
          const filtered = this.kalmanFilters[i].update(landmark.x, landmark.y);

          // Temporal smoothing with history (reduced frames for less delay)
          let smoothedLandmark = { ...landmark };

          if (this.history.length > 0) {
            // Use only last 2 frames for minimal delay
            const recentFrames = this.history.slice(-2);
            const validFrames = recentFrames.filter(f => f.landmarks && f.landmarks[i]);

            if (validFrames.length > 0) {
              let avgX = 0, avgY = 0, avgZ = 0;
              validFrames.forEach(frame => {
                avgX += frame.landmarks[i].x;
                avgY += frame.landmarks[i].y;
                avgZ += frame.landmarks[i].z;
              });
              avgX /= validFrames.length;
              avgY /= validFrames.length;
              avgZ /= validFrames.length;

              // Blend current with historical average (Kalman already smoothed)
              smoothedLandmark.x = filtered.x * (1 - smoothingFactor) + avgX * smoothingFactor;
              smoothedLandmark.y = filtered.y * (1 - smoothingFactor) + avgY * smoothingFactor;
              smoothedLandmark.z = landmark.z * (1 - smoothingFactor) + avgZ * smoothingFactor;
            } else {
              smoothedLandmark.x = filtered.x;
              smoothedLandmark.y = filtered.y;
            }
          } else {
            smoothedLandmark.x = filtered.x;
            smoothedLandmark.y = filtered.y;
          }

          // Reset missing frames counter
          this.missingFrames[i] = 0;

          smoothedLandmarks.push(smoothedLandmark);
        });

        this.addFrame(smoothedLandmarks);
        return smoothedLandmarks;
      }

      interpolateFromHistory() {
        if (this.history.length < 2) return null;

        // Get the two most recent valid frames
        const validFrames = this.history.filter(f => f.landmarks).slice(-2);
        if (validFrames.length < 2) return null;

        const interpolated = [];
        const frame1 = validFrames[validFrames.length - 2].landmarks;
        const frame2 = validFrames[validFrames.length - 1].landmarks;

        frame1.forEach((landmark, i) => {
          if (frame2[i]) {
            // Use Kalman filter prediction if available
            if (this.kalmanFilters[i]) {
              const predicted = this.kalmanFilters[i].predict();
              if (predicted) {
                interpolated.push({
                  x: predicted.x,
                  y: predicted.y,
                  z: (landmark.z + frame2[i].z) / 2,
                  visibility: Math.min(landmark.visibility, frame2[i].visibility) * 0.8
                });

                // Increment missing frames counter
                this.missingFrames[i] = (this.missingFrames[i] || 0) + 1;

                // Stop interpolating if too many frames missing
                if (this.missingFrames[i] > this.maxGapFrames) {
                  return; // Exit this iteration
                }

                return; // Skip to next iteration (replaces continue)
              }
            }

            // Linear interpolation fallback
            interpolated.push({
              x: (landmark.x + frame2[i].x) / 2,
              y: (landmark.y + frame2[i].y) / 2,
              z: (landmark.z + frame2[i].z) / 2,
              visibility: Math.min(landmark.visibility, frame2[i].visibility) * 0.8
            });
          }
        });

        return interpolated.length === frame1.length ? interpolated : null;
      }

      reset() {
        this.history = [];
        this.kalmanFilters = {};
        this.missingFrames = {};
      }
    }

    document.addEventListener('DOMContentLoaded', () => {
      log('Page loaded. Ready to upload video.');

      const videoUpload = document.getElementById('videoUpload');
      const playerContainer = document.getElementById('playerContainer');
      const resultsVideo = document.getElementById('resultsVideo');
      const resultsCanvas = document.getElementById('resultsCanvas');
      const processingCanvas = document.getElementById('processingCanvas');
      const processingCtx = processingCanvas.getContext('2d', { willReadFrequently: true });

      // Settings
      const contrastSlider = document.getElementById('contrast');
      const brightnessSlider = document.getElementById('brightness');
      const sharpnessSlider = document.getElementById('sharpness');
      const smoothingSlider = document.getElementById('smoothing');
      const contrastValue = document.getElementById('contrastValue');
      const brightnessValue = document.getElementById('brightnessValue');
      const sharpnessValue = document.getElementById('sharpnessValue');
      const smoothingValue = document.getElementById('smoothingValue');

      let settings = {
        contrast: 1.3,
        brightness: 1.1,
        sharpness: 1.5,
        smoothing: 0.3  // Reduced from 0.7 for less delay
      };

      contrastSlider.addEventListener('input', (e) => {
        settings.contrast = parseFloat(e.target.value);
        contrastValue.textContent = settings.contrast;
      });

      brightnessSlider.addEventListener('input', (e) => {
        settings.brightness = parseFloat(e.target.value);
        brightnessValue.textContent = settings.brightness;
      });

      sharpnessSlider.addEventListener('input', (e) => {
        settings.sharpness = parseFloat(e.target.value);
        sharpnessValue.textContent = settings.sharpness;
      });

      smoothingSlider.addEventListener('input', (e) => {
        settings.smoothing = parseFloat(e.target.value);
        smoothingValue.textContent = settings.smoothing;
      });

      let poseInitialized = false;
      let pose;
      // Reduced history for less delay: 5 frames instead of 10, max gap 3 instead of 5
      let temporalSmoother = new TemporalSmoother(5, 3);

      // Initialize MediaPipe Pose
      try {
        log('Initializing MediaPipe Pose with maximum model complexity...');
        pose = new Pose({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5.1675469404/${file}`;
          }
        });

        pose.setOptions({
          modelComplexity: 2,
          smoothLandmarks: true,
          enableSegmentation: false,
          smoothSegmentation: false,
          minDetectionConfidence: 0.3,
          minTrackingConfidence: 0.3
        });

        pose.onResults(onResults);
        log('MediaPipe Pose initialized with advanced tracking');
        poseInitialized = true;
      } catch (error) {
        log('Error initializing MediaPipe: ' + error.message);
        console.error(error);
      }

      // Handle video upload
      videoUpload.addEventListener('change', async (event) => {
        const file = event.target.files[0];
        if (!file) {
          log('No file selected.');
          return;
        }

        log(`Video selected: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`);

        // Show player container
        playerContainer.classList.remove('hidden');
        console.log('Player container shown');

        // Create object URL and set video source
        const videoURL = URL.createObjectURL(file);
        resultsVideo.src = videoURL;
        resultsVideo.style.display = 'block';

        console.log('Video source set:', videoURL);
        console.log('Video element:', resultsVideo);

        // Reset temporal smoother for new video
        temporalSmoother.reset();

        // Force video load
        try {
          await resultsVideo.load();
          log('Video loading initiated...');
        } catch (error) {
          console.error('Error loading video:', error);
          log('Error loading video: ' + error.message);
        }
      });

      resultsVideo.addEventListener('loadedmetadata', () => {
        log(`Video loaded! Resolution: ${resultsVideo.videoWidth}x${resultsVideo.videoHeight}. Click play to start.`);
        updateCanvasSize();
      });

      // Update canvas size to match displayed video
      function updateCanvasSize() {
        // Use displayed dimensions (clientWidth/Height) for canvas
        const displayWidth = resultsVideo.clientWidth;
        const displayHeight = resultsVideo.clientHeight;

        // Set canvas drawing dimensions to match video native resolution
        resultsCanvas.width = resultsVideo.videoWidth;
        resultsCanvas.height = resultsVideo.videoHeight;

        // Set processing canvas to same size
        processingCanvas.width = resultsVideo.videoWidth;
        processingCanvas.height = resultsVideo.videoHeight;

        console.log(`Video native: ${resultsVideo.videoWidth}x${resultsVideo.videoHeight}`);
        console.log(`Video displayed: ${displayWidth}x${displayHeight}`);
        console.log(`Canvas: ${resultsCanvas.width}x${resultsCanvas.height}`);
      }

      // Update canvas size when video is resized or loaded
      resultsVideo.addEventListener('loadeddata', updateCanvasSize);
      window.addEventListener('resize', updateCanvasSize);

      resultsVideo.addEventListener('error', (e) => {
        log('Error loading video: ' + e.message);
        console.error('Video error:', e);
      });

      resultsVideo.addEventListener('play', () => {
        log('Video playing. AI analysis with temporal smoothing active...');

        if (!poseInitialized) {
          log('Warning: MediaPipe Pose not initialized!');
          return;
        }

        processVideoFrame();
      });

      resultsVideo.addEventListener('pause', () => {
        log('Video paused.');
      });

      resultsVideo.addEventListener('ended', () => {
        log('Video ended. Upload another video to analyze.');
      });

      // Preprocess video frame
      function preprocessFrame(videoElement) {
        const width = processingCanvas.width;
        const height = processingCanvas.height;

        processingCtx.drawImage(videoElement, 0, 0, width, height);

        const imageData = processingCtx.getImageData(0, 0, width, height);
        const data = imageData.data;

        for (let i = 0; i < data.length; i += 4) {
          data[i] = ((data[i] / 255 - 0.5) * settings.contrast + 0.5) * 255 * settings.brightness;
          data[i + 1] = ((data[i + 1] / 255 - 0.5) * settings.contrast + 0.5) * 255 * settings.brightness;
          data[i + 2] = ((data[i + 2] / 255 - 0.5) * settings.contrast + 0.5) * 255 * settings.brightness;
        }

        if (settings.sharpness > 0) {
          const sharpened = applySharpen(imageData, settings.sharpness);
          processingCtx.putImageData(sharpened, 0, 0);
        } else {
          processingCtx.putImageData(imageData, 0, 0);
        }

        return processingCanvas;
      }

      function applySharpen(imageData, amount) {
        const width = imageData.width;
        const height = imageData.height;
        const data = imageData.data;
        const output = processingCtx.createImageData(width, height);

        const kernel = [
          0, -1 * amount, 0,
          -1 * amount, 1 + 4 * amount, -1 * amount,
          0, -1 * amount, 0
        ];

        for (let y = 1; y < height - 1; y++) {
          for (let x = 1; x < width - 1; x++) {
            for (let c = 0; c < 3; c++) {
              let sum = 0;
              for (let ky = -1; ky <= 1; ky++) {
                for (let kx = -1; kx <= 1; kx++) {
                  const idx = ((y + ky) * width + (x + kx)) * 4 + c;
                  const kidx = (ky + 1) * 3 + (kx + 1);
                  sum += data[idx] * kernel[kidx];
                }
              }
              const outIdx = (y * width + x) * 4 + c;
              output.data[outIdx] = Math.max(0, Math.min(255, sum));
            }
            const outIdx = (y * width + x) * 4 + 3;
            output.data[outIdx] = 255;
          }
        }

        return output;
      }

      async function processVideoFrame() {
        if (resultsVideo.paused || resultsVideo.ended) {
          return;
        }

        try {
          const processedFrame = preprocessFrame(resultsVideo);
          await pose.send({ image: processedFrame });
        } catch (error) {
          console.error('Error processing frame:', error);
        }

        requestAnimationFrame(processVideoFrame);
      }

      function onResults(results) {
        const canvasCtx = resultsCanvas.getContext('2d');

        canvasCtx.save();
        canvasCtx.clearRect(0, 0, resultsCanvas.width, resultsCanvas.height);

        // Apply temporal smoothing and Kalman filtering
        const smoothedLandmarks = temporalSmoother.smooth(
          results.poseLandmarks,
          settings.smoothing
        );

        if (smoothedLandmarks) {
          // Draw with smoothed landmarks
          drawConnectors(
            canvasCtx,
            smoothedLandmarks,
            POSE_CONNECTIONS,
            { color: '#00FF00', lineWidth: 6 }
          );

          drawLandmarks(
            canvasCtx,
            smoothedLandmarks,
            { color: '#FF0000', lineWidth: 3, radius: 8 }
          );
        }

        canvasCtx.restore();
      }
    });
  </script>
</body>
</html>
